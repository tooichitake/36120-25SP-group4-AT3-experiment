## 0. Import Packages
import sys
sys.path.append('..')

from bitcoin import (
    BitcoinDataProcessor,
    plot_candlestick,
    plot_target_distribution,
    plot_features_correlation,
    evaluate_regression,
    plot_regression_results,
    save_model,
    load_model,
    analyze_optimal_feature_count,
    plot_optimal_feature_count
)

# Import prepare_linear_regression_data directly from features module
from bitcoin.features import prepare_linear_regression_data

from sklearn.linear_model import LinearRegression
---
## C. Data Understanding
### C.1   Load Datasets
processor = BitcoinDataProcessor()
df = processor.load_raw_data()
df.head()
### C.2 Define Target variable
target_name = 'next_day_high'
### C.3 Create Target variable
df = processor.create_target_variable(df)
### C.4 Explore Target variable
plot_target_distribution(df)
### C.5 Explore OHLC Price, Volume, and Market Cap
plot_candlestick(df)
---
## D. Feature Selection
# Generate technical indicators for feature selection analysis
df_cleaned = processor.clean_timestamp_columns(df)
df_clean = processor.add_technical_indicators(df_cleaned)
correlations = processor.analyze_features_correlation(df_clean)
plot_features_correlation(correlations)
### D.2 Approach "Optimal Feature Count Analysis"
# Test different top-N feature configurations
results_df = analyze_optimal_feature_count(df_clean)

# Visualize performance curves
plot_optimal_feature_count(results_df)
### D.3 Final Selection of Features
# Final list of optimal features selected for modeling (30 features)
features_list = [
    'close', 'VWAP', 'high', 'low', 'marketCap', 'open',
    'TEMA_20', 'SMA_7', 'DEMA_20', 'HMA_20', 'EMA_12', 'KCBe_20_2.0',
    'DCM_20_20', 'KCUe_20_2.0', 'KCLe_20_2.0', 'DCU_20_20',
    'BBM_20_2.0', 'SMA_20', 'EMA_26', 'BBU_20_2.0',
    'DCL_20_20', 'BBL_20_2.0', 'EMA_50', 'SMA_50',
    'SMA_200', 'ATRr_14', 'AD', 'OBV', 'volume', 'MACDs_12_26_9'
]
---
## E. Data Preparation
### E.1 Data Transformation "Remove Timestamp Columns"
df_cleaned = processor.clean_timestamp_columns(df)
df_cleaned.head()
---
## F. Feature Engineering
df_clean = processor.add_technical_indicators(df_cleaned)
df_clean.head()
---
## G. Data Preparation for Modeling
### G.1 Split Datasets
train_df, val_df, test_df = processor.time_series_split(df_clean)
### G.2 Data Preparation - No Standardization
data = prepare_linear_regression_data(train_df, val_df, test_df)

X_train, y_train = data['X_train'], data['y_train']
X_val, y_val = data['X_val'], data['y_val']
X_test, y_test = data['X_test'], data['y_test']
feature_cols = data['feature_cols']
### J.2 Model Configuration
# Initialize sklearn LinearRegression (no hyperparameters needed)
model = LinearRegression()
model = LinearRegression()
model.fit(X_train, y_train)

evaluate_regression(y_train, model.predict(X_train), set_name='Train')
evaluate_regression(y_val, model.predict(X_val), set_name='Validation')

model_path = '../models/linear_regression_bitcoin.pkl'
save_model(model, model_path)
### J.4 Model Technical Performance

> Provide some explanations on model performance

model = load_model(model_path)

y_pred = model.predict(X_test)
evaluate_regression(y_test, y_pred, set_name='Test')
plot_regression_results(y_test, y_pred)